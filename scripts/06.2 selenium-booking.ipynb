{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéì **Professor**: Apostolos Filippas\n",
    "\n",
    "### üìò **Class**: Web Analytics\n",
    "\n",
    "### üìã **Topic**: Using Selenium to Parse Web Content\n",
    "\n",
    "üö´ **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Static content üîí vs. Dynamic content üçÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/apostolosfilippas/wa/e60f312c3435e31da72af81baed7194daf98cf11/assets/selenium-1.svg\" width=\"800\" height=\"480\">\n",
    "<br>\n",
    "</div>\n",
    "\n",
    "> üîí **Static content** is any file that is stored in a server and is the same every time it is delivered to users. Unless the developer makes changes themselves, the web page always remains the same. It is like a newspaper: once an issue of a newspaper is published, it features the same articles and photos all day for everyone who picks up a copy.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "        <img src=\"https://github.com/apostolosfilippas/wa/blob/main/assets/selenium-2.png?raw=true\" title=\"source: imgur.com\" width=\"350\" height=\"350\" />\n",
    "</div>\n",
    "\n",
    "> üçÉ **Dynamic content** is content that changes based on factors specific to the user such as time of visit, location, and device. A dynamic webpage will not look the same for everybody, and it can change as users interact with it ‚Äì like if a newspaper could rewrite itself as someone is reading it. This makes webpages more personalized and more interactive.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "        <img src=\"https://github.com/apostolosfilippas/wa/blob/main/assets/selenium-3.png?raw=true\" title=\"source: imgur.com\" width=\"350\" height=\"350\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. How do dynamic websites work?\n",
    "\n",
    "There are many external services that dynamic webpages interact with. Here we cover 3 common services:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üåê Server-side scripting** \n",
    "\n",
    "When a user requests a webpage, the server processes the script, and interacts with databases or external services. Then, it sends the dynamically generated HTML back to the user's browser.\n",
    "\n",
    "**Used for**: detecting that you are logging in from a certain geographic location, and shows you relevant information for that location\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://github.com/apostolosfilippas/wa/blob/main/assets/selenium-4.png?raw=true\" title=\"source: imgur.com\" width=\"400\" height=\"300\" />\n",
    "</div>\n",
    "\n",
    "### **üíª Client-side scripting** \n",
    "#### This involves using **_JavaScript_** to manipulate the content and behavior of web pages directly within the user's browser (i.e., click, scroll, play, pause, and more). It allows for interactive features, such as real-time updates and dynamic animations.\n",
    "***Used for**: Scrolling and clicking, form validation (submitting a form), real-time chat and messaging, image carousels\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://github.com/apostolosfilippas/wa/blob/main/assets/selenium-5.png?raw=true\" title=\"source: imgur.com\" width=\"400\" height=\"300\" />\n",
    "</div>\n",
    "\n",
    "### **‚òéÔ∏è Application Programming Interfaces (APIs)** \n",
    "#### APIs enable different systems to communicate and share data. In the dynamic websites, APIs can connect to external services or retrieve data from other sources, such as social media platforms, weather services, or payment gateways.\n",
    "**Used for**: Allowing users to view and interact with external services without having to leave the website (ex. live Twitter feeds, PayPal).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://github.com/apostolosfilippas/wa/blob/main/assets/selenium-6.png?raw=true\" title=\"source: imgur.com\" width=\"375\" height=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Beautiful Soup alone is not enough to scrape web content?\n",
    "- **Beautiful Soup**: It does only static scraping. Static scraping doesn't take JavaScript into consideration. When using Beautiful Soup to fetch web pages from the servers, it doesn't interact with the browser. \n",
    "\n",
    "- **Selenium**: In many cases, you need data that are hidden in components which get rendered on clicking JavaScript links. For example, for long reviews on many websites, you often need to click \"read more\" to view the full content. If you scraped a website using BeautifulSoup without clicking the \"read more\" button, you would only get part of that review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Getting started with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we start by importing all the useful packages. \n",
    "\n",
    "Note that to be able to follow along, you should have followed the steps in the \"Before class\" portion of Lecture 6.\n",
    "\n",
    "We will be using chrome throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium webdriver-manager beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # type: ignore\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "import time \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above:\n",
    "- **time** will allow us to build \"breaks\" into our code to slow it down.\n",
    "- **pandas** will allow us to store data that we parsed from the website (you will learn more about this next week)\n",
    "\n",
    "\n",
    "Below:\n",
    "- The following scripts will open an instance of the Chrome browser. The instance of Chrome that opened will indicate that \"Chrome is now being controlled by automated test software\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a browser object-- this should open a chrome browser using selenium\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to a website\n",
    "browser.get(\"http://www.newyorktimes.com/\")\n",
    "time.sleep(2)\n",
    "browser.get(\"https://www.openai.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "browser.quit()\n",
    "\n",
    "# take a look at other browser methods\n",
    "# browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you're ready to use this powerful tool! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Navigating around a website with Selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  initialize our browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "time.sleep(1)\n",
    "browser.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "# let's go to the review page of Brooklyn Hotel on Booking.com\n",
    "link = \"https://www.booking.com/hotel/us/bklyn-house-new-york-brooklyn.html\"\n",
    "\n",
    "browser.get(link)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Just like HTML is used to find static content, we can use __**XML**__ (Extensible Markup Language) to find and interact with dynamic content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML\n",
    "- XML is a markup language,designed to store, structure, and transport data or information.\n",
    "- It focuses on representing the content of data rather than specifying how it should be displayed (unlike HTML)\n",
    "- XML is widely used for data interchange and storage, providing a standardized way to format and organize data.\n",
    "- XML documents use tags to enclose data elements, creating a hierarchical structure. For example:\n",
    "\n",
    "```xml\n",
    "<bookstore>\n",
    "  <book>\n",
    "    <title lang=\"en\">Harry Potter and the mid-life crisis</title>\n",
    "    <description>Go on a journey with Harry Potter and his friends as they navigate the challenges of middle age by buying a Porsche.</description>\n",
    "    <price>29.99</price>\n",
    "  </book>\n",
    "</bookstore>\n",
    "```\n",
    "\n",
    "## XPath\n",
    "- XPath (XML Path Language) is a query language used in Selenium to navigate and locate elements within a web page's DOM (Document Object Model).\n",
    "- XPath is used to locate and interact with elements within XML or HTML documents, making it particularly useful for tasks like web scraping and automated testing. While XPath is often associated with XML because it was originally designed for XML documents, it can also be applied to HTML documents. \n",
    "- XPath allows you to traverse the hierarchy of elements within both XML and HTML, making it a valuable tool for selecting and manipulating data in these structured documents. So, while they are separate concepts, XPath is frequently used in conjunction with XML and HTML to access and work with data in these formats.\n",
    "- You can find the XPATH by right click the web page, click the inspect button and select the element you want to check. It's very similar to access content with id, class and other attributes, but gives us even more freedom.\n",
    "\n",
    "A sample XPath is shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/apostolosfilippas/wa/refs/heads/main/assets/selenium-7.webp\" width=\"800\" height=\"280\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `//`:  This selects all elements in the document that match the criteria that follow, regardless of their location within the document's hierarchy.\n",
    "- `tagname`: This selects all elements with the specified tag name.\n",
    "- `[@attribute='value']`: This selects all elements that have the specified attribute with a value equal to the specified value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating content using XPath \n",
    "\n",
    "Now let's click apply some filters using Selenium, so that we only see summer reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"<a href=\"https://imgur.com/a/3Aq34yG\"><img src=\"https://i.imgur.com/z2DEFYU.png\" title=\"source: imgur.com\" width=\"250\" height=\"250\" /></a>\"\n",
    "\n",
    "<a href=\"https://imgur.com/a/EHpkA6G\"><img src=\"https://i.imgur.com/GElF4on.png\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can build the XPath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the elements on this web page, we found that:\n",
    "\n",
    "- **tagname** = a(it is a link/anchor element)\n",
    "- **attribute** = data-testid\n",
    "- **value** = \"Property-Header-Nav-Tab-Trigger-reviews\"\n",
    "\n",
    "**\n",
    "\n",
    "From here we can fill in those parameters into our xpath:\n",
    "\n",
    "//a[@data-testid='Property-Header-Nav-Tab-Trigger-reviews']\n",
    "\n",
    "However website structures can change frequently so we can also use \n",
    "\n",
    "//a[contains(., 'Guest reviews')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xpath to click the \"Guest Reviews\" button/link\n",
    "\n",
    "# Use xpath to click the \"Guest reviews\" tab\n",
    "xp = (\"//a[contains(.,'Guest reviews')]\"\n",
    "      \" | //button[contains(.,'Guest reviews')]\"\n",
    "      \" | //a[.//span[contains(.,'Guest reviews')]]\"\n",
    "      \" | //button[.//span[contains(.,'Guest reviews')]]\")\n",
    "\n",
    "time.sleep(1)\n",
    "el = browser.find_element(By.XPATH, xp)\n",
    "# scroll so it's on-screen (helps avoid hidden/covered element issues)\n",
    "browser.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", el)\n",
    "time.sleep(1)\n",
    "# Re-find the element after scrolling to avoid stale reference\n",
    "el = browser.find_element(By.XPATH, xp)\n",
    "el.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "# Close any popup that might be blocking\n",
    "close_xp = \"//button[contains(@aria-label, 'Close')]\"\n",
    "try:\n",
    "    el = browser.find_element(By.XPATH, close_xp)\n",
    "    el.click()\n",
    "    time.sleep(1)\n",
    "except:\n",
    "    pass  # No popup to close\n",
    "\n",
    "# Click \"Show more\" button\n",
    "show_more_xp = \"//button[contains(., 'Show more')]\"\n",
    "el = browser.find_element(By.XPATH, show_more_xp)\n",
    "browser.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", el)\n",
    "time.sleep(1)\n",
    "el = browser.find_element(By.XPATH, show_more_xp)\n",
    "el.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Click \"Show less\" button  \n",
    "show_less_xp = \"//button[contains(., 'Show less')]\"\n",
    "el = browser.find_element(By.XPATH, show_less_xp)\n",
    "el.click()\n",
    "time.sleep(2)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to identify the button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, we can right click the element we want > Copy > Copy XPath**\n",
    "\n",
    "This will give you the Absolute XPath\n",
    "\n",
    "<a href=\"https://imgur.com/a/9nbYj0y\"><img src=\"https://i.imgur.com/Nb2Jczu.png\" title=\"source: imgur.com\" width = \"600\" height=\"200\" /></a>\n",
    "\n",
    "For the show more button, it looks like this:\n",
    "\n",
    "//*[@id=\"b2hotelPage\"]/div[26]/div/div/div/div/div[2]/div/div[4]/div/div[2]/div/button[2]/span\n",
    "\n",
    "\n",
    "\n",
    "**Why don't we do this instead?**\n",
    "\n",
    "- It makes your code longer\n",
    "- Your code will be more likely to break if anything changes on the web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if there are multiple elements with that XPath? How do we find them all?\n",
    "\n",
    "There are multiple buttons on the page. Let's find all of them and inspect what they contain.\n",
    "\n",
    "Here is an XPath that matches buttons on the page:\n",
    "\n",
    "//button[@type='button']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing all the buttons on a page\n",
    "xpath_buttons = \"//button[@type='button']\"\n",
    "\n",
    "time.sleep(2)\n",
    "elements = browser.find_elements(By.XPATH, xpath_buttons)\n",
    "\n",
    "print(type(elements))\n",
    "print(len(elements))\n",
    "elements[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do I know which element is which??**\n",
    "\n",
    "**We can extract the innerHTML or property or text information by .get_attribute('innerHTML'), .get_property() or .text methods** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all buttons in the page (or popup)\n",
    "elements = browser.find_elements(By.XPATH, \"//button\")\n",
    "\n",
    "print(len(elements))   # how many buttons total?\n",
    "for ind, element in enumerate(elements[:15]):  # just show first 15\n",
    "    print(f\"{ind}. {element.text} | {element.get_attribute('innerHTML')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there **another** way of identifying the button?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nChecking for reviews content...\")\n",
    "\n",
    "# First check main page content\n",
    "found_in_main = False\n",
    "try:\n",
    "    # Look for review-related elements in main content\n",
    "    main_review_selectors = [\n",
    "        \"//*[contains(text(), 'Select topics')]\",\n",
    "        \"//*[contains(text(), 'Filter reviews')]\", \n",
    "        \"//*[contains(text(), 'All reviews')]\",\n",
    "        \"//div[contains(@class, 'review')]\",\n",
    "        \"//*[contains(text(), 'Guest review')]\"\n",
    "    ]\n",
    "    \n",
    "    for selector in main_review_selectors:\n",
    "        try:\n",
    "            element = browser.find_element(By.XPATH, selector)\n",
    "            print(f\"Found reviews in main content with selector: {selector}\")\n",
    "            found_in_main = True\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    if not found_in_main:\n",
    "        print(\"Reviews not found in main content\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error checking main content: {e}\")\n",
    "\n",
    "# STEP 3: If not in main content, check iframes\n",
    "if not found_in_main:\n",
    "    print(\"\\nChecking iframes for reviews...\")\n",
    "    \n",
    "    # List iframes\n",
    "    iframes = browser.find_elements(By.TAG_NAME, \"iframe\")\n",
    "    print(f\"iframes: {len(iframes)}\")\n",
    "\n",
    "    # Try each iframe until we see the reviews content\n",
    "    found = False\n",
    "    for i, f in enumerate(iframes):\n",
    "        browser.switch_to.frame(f)\n",
    "        try:\n",
    "            # Look for various review-related text/elements\n",
    "            review_indicators = [\n",
    "                \"//*[contains(text(), 'Select topics to read reviews')]\",\n",
    "                \"//*[contains(text(), 'Filter reviews')]\",\n",
    "                \"//*[contains(text(), 'All reviews')]\", \n",
    "                \"//div[contains(@class, 'review')]\",\n",
    "                \"//*[contains(text(), 'Guest review')]\"\n",
    "            ]\n",
    "            \n",
    "            for indicator in review_indicators:\n",
    "                try:\n",
    "                    browser.find_element(By.XPATH, indicator)\n",
    "                    print(f\"found reviews frame: {i} with indicator: {indicator}\")\n",
    "                    found = True\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if found:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iframe {i}: {e}\")\n",
    "        \n",
    "        browser.switch_to.default_content()\n",
    "\n",
    "    if not found:\n",
    "        browser.switch_to.default_content()\n",
    "        print(\"reviews frame not found\")\n",
    "        \n",
    "        # Debug: Let's see what's actually in each iframe\n",
    "        print(\"\\nDEBUG - Content preview of each iframe:\")\n",
    "        for i, f in enumerate(iframes):\n",
    "            browser.switch_to.frame(f)\n",
    "            try:\n",
    "                body_text = browser.find_element(By.TAG_NAME, \"body\").text[:100]\n",
    "                print(f\"iframe {i}: {body_text}\")\n",
    "            except:\n",
    "                print(f\"iframe {i}: could not read content\")\n",
    "            browser.switch_to.default_content()\n",
    "    else:\n",
    "        print(\"Reviews content successfully found!\")\n",
    "        # You're now in the correct frame (if it was in an iframe)\n",
    "        # Continue with your reviews scraping code here     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Using the CSS selector to find elements\n",
    "\n",
    "We can use CSS Selectors instead of XPath to find and interact with elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **What is a CSS Selector?**\n",
    "\n",
    "A CSS selector is like a set of instructions that tells a web browser how to find and style elements on a web page. Remember that elements have different attributes; we can use CSS to look for elements with specific attribute values.\n",
    "\n",
    "\n",
    "##### **Examples of CSS Selectors:**\n",
    "1. Element Selector\n",
    "\n",
    "    < button > or < a > will point to elements with those respective types\n",
    "\n",
    "2. Class Selector --> .\n",
    "    \n",
    "    '.expand' points to all elements with class='expand'\n",
    "\n",
    "3. ID Selector--> #\n",
    "    \n",
    "     #submit-button points to the element with id=\"submit-button\"\n",
    "\n",
    "4. Attribute Selector --> [type=\" \"] [attribute=\"value\"]\n",
    "\n",
    "    eg. [ type=\"text\" ] points to all elements with type=\"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_button = \"button, a.bui-button, a[data-testid*='review'], *[data-testid*='review']\"\n",
    "\n",
    "time.sleep(2)\n",
    "cands = browser.find_elements(By.CSS_SELECTOR, example_button)\n",
    "\n",
    "print(\"buttons found:\", len(cands))\n",
    "for i, el in enumerate(cands[:10]):  # show the first 10\n",
    "    # Try getting text from the element or its children\n",
    "    text = el.text.strip()\n",
    "    if not text:  # If no direct text, try getting from child elements\n",
    "        try:\n",
    "            text = el.find_element(By.XPATH, \".//span | .//div\").text.strip()\n",
    "        except:\n",
    "            text = \"no text found\"\n",
    "    print(i, repr(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How did this work?** \n",
    "\n",
    "\"button\": selects all button elements\n",
    "\n",
    "'a.bui-button': selects all \"a\" elements that have class 'bui-button'\n",
    "\n",
    "a[data-testid*='review']: Selects all \"a\" elements where the data-testid attribute contains the text 'review'\n",
    "\n",
    "[data-testid*='review']: Selects any element where \"data-testid\" contains 'review'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to locate elements using selenium. For the full list, you can refer to: https://selenium-python.readthedocs.io/locating-elements.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the webpage is dynamically generated, we often need to click the **read more** button to reveal content. \n",
    "- For example, some long reviews are only partially available on TripAdvisor-- you would need to click on \"Read More\" to access the full review. Other short reviews are fully available.\n",
    "\n",
    "## Trying to click a button that doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already expanded this review. Since we interacted with a dynamic page, the button is no longer on it now.\n",
    "# what will happen if we try to click the button that doesn't exist?\n",
    "\n",
    "browser.find_element(By.CSS_SELECTOR,example_button).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to check if the button exists on the page\n",
    "def check_exists_by_css(selector):\n",
    "    try:\n",
    "        browser.find_element(By.CSS_SELECTOR,selector)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_exists_by_xpath(xp):\n",
    "    try:\n",
    "        browser.find_element(By.XPATH,xp)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we try to find a nonsense element, it will just return False instead of breaking the code\n",
    "\n",
    "check_exists_by_css('hahaha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes hotel responses are collapsed - let's expand them\n",
    "# Look for \"Continue reading\" buttons in hotel responses\n",
    "\n",
    "continue_reading_xp = \"//button[contains(., 'Continue reading')]\"\n",
    "\n",
    "# Find all \"Continue reading\" buttons\n",
    "continue_buttons = browser.find_elements(By.XPATH, continue_reading_xp)\n",
    "\n",
    "print(f\"Found {len(continue_buttons)} 'Continue reading' buttons\")\n",
    "\n",
    "# Click each one to expand the hotel responses\n",
    "for button in continue_buttons:\n",
    "    try:\n",
    "        # Scroll to button\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", button)\n",
    "        time.sleep(0.5)\n",
    "        # Click it\n",
    "        button.click()\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        # If it fails (maybe button disappeared), just continue\n",
    "        continue\n",
    "\n",
    "print(\"Expanded all hotel responses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Combining Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas we cna use Selenium alone to scrape content, we prefer to use it together with beautifulsoup to make our lives easier. \n",
    "\n",
    "The complete workflow would be like:\n",
    "1. Using Selenium to automate web browser interaction so that hidden content can be made available by automating actions such as the button clicks, screen scrolling and so on\n",
    "2. After all the content we want to parse is revealed, we'll use BeautifulSoup to parse it like we did in Lecture 5\n",
    "\n",
    "---\n",
    "# 7. Challenge\n",
    "\n",
    "1. Use Selenium to go through the reviews \n",
    "2. Use BeautifulSoup to parse the content of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Initialize lists\n",
    "authors = []\n",
    "ratings = []\n",
    "review_titles = []\n",
    "positive_parts = []\n",
    "negative_parts = []\n",
    "room_types = []\n",
    "\n",
    "# Open browser and go to reviews\n",
    "link = \"https://www.booking.com/hotel/us/bklyn-house-new-york-brooklyn.html#tab-reviews\"\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(link)\n",
    "print(\"Opened browser, waiting for page to load...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Make sure we're on the reviews section - click it if needed\n",
    "try:\n",
    "    reviews_tab_xp = \"//a[contains(.,'Guest reviews')] | //button[contains(.,'Guest reviews')]\"\n",
    "    reviews_tab = browser.find_element(By.XPATH, reviews_tab_xp)\n",
    "    browser.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", reviews_tab)\n",
    "    time.sleep(1)\n",
    "    reviews_tab.click()\n",
    "    print(\"Clicked Guest reviews tab\")\n",
    "    time.sleep(3)\n",
    "except:\n",
    "    print(\"Guest reviews already open or couldn't find tab\")\n",
    "\n",
    "# Loop through 10 pages\n",
    "for page in range(10):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"SCRAPING PAGE {page + 1}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    # Wait a bit for any dynamic content to load\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Get page source and parse\n",
    "    page_source = browser.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    # Find review cards\n",
    "    cards = soup.find_all(\"div\", {\"data-testid\": \"review-card\"})\n",
    "    print(f\"Found {len(cards)} review cards on this page\")\n",
    "    \n",
    "    # If no cards found, try to debug\n",
    "    if len(cards) == 0:\n",
    "        print(\"WARNING: No review cards found!\")\n",
    "        print(\"Looking for any review-related elements...\")\n",
    "        review_divs = soup.find_all(\"div\", {\"data-testid\": lambda x: x and \"review\" in x.lower() if x else False})\n",
    "        print(f\"Found {len(review_divs)} divs with 'review' in data-testid\")\n",
    "        if len(review_divs) > 0:\n",
    "            print(\"First few:\")\n",
    "            for div in review_divs[:3]:\n",
    "                print(f\"  - {div.get('data-testid')}\")\n",
    "        break\n",
    "    \n",
    "    # Extract data from each card\n",
    "    for i, card in enumerate(cards):\n",
    "        print(f\"Processing review {i+1}...\")\n",
    "        \n",
    "        # Get author name\n",
    "        author_elem = card.find(\"div\", class_=\"b08850ce41 f546354b44\")\n",
    "        author = author_elem.get_text(strip=True) if author_elem else \"No author\"\n",
    "        authors.append(author)\n",
    "        \n",
    "        # Get rating\n",
    "        rating_elem = card.find(\"div\", class_=\"bc946a29db\")\n",
    "        if rating_elem:\n",
    "            rating_text = rating_elem.get_text(strip=True)\n",
    "            try:\n",
    "                numbers = re.findall(r'\\d+\\.?\\d*', rating_text)\n",
    "                rating = float(numbers[0]) if numbers else None\n",
    "            except:\n",
    "                rating = None\n",
    "        else:\n",
    "            rating = None\n",
    "        ratings.append(rating)\n",
    "        \n",
    "        # Get review title\n",
    "        title_elem = card.find(\"h4\", {\"data-testid\": \"review-title\"})\n",
    "        title = title_elem.get_text(strip=True) if title_elem else \"No title\"\n",
    "        review_titles.append(title)\n",
    "        \n",
    "        # Get room type\n",
    "        room_elem = card.find(string=re.compile(r\"Room\"))\n",
    "        room_type = room_elem.strip() if room_elem else \"No room type\"\n",
    "        room_types.append(room_type)\n",
    "        \n",
    "        # Get positive review\n",
    "        positive_elem = card.find(\"div\", {\"data-testid\": \"review-positive-text\"})\n",
    "        positive_text = positive_elem.get_text(strip=True) if positive_elem else \"\"\n",
    "        positive_parts.append(positive_text)\n",
    "        \n",
    "        # Get negative review\n",
    "        negative_elem = card.find(\"div\", {\"data-testid\": \"review-negative-text\"})\n",
    "        negative_text = negative_elem.get_text(strip=True) if negative_elem else \"\"\n",
    "        negative_parts.append(negative_text)\n",
    "    \n",
    "    print(f\"Completed page {page + 1}: scraped {len(cards)} reviews\")\n",
    "    \n",
    "    # Try to go to next page (if not on last page)\n",
    "    if page < 9:\n",
    "        try:\n",
    "            # Look for \"Next page\" button\n",
    "            next_button_xp = \"//button[@aria-label='Next page']\"\n",
    "            next_button = browser.find_element(By.XPATH, next_button_xp)\n",
    "            browser.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", next_button)\n",
    "            time.sleep(1)\n",
    "            next_button.click()\n",
    "            print(f\"Clicked 'Next page' button, waiting for page {page + 2} to load...\")\n",
    "            time.sleep(4)  # Increased wait time\n",
    "        except Exception as e:\n",
    "            print(f\"Could not find next page button - stopping at page {page + 1}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "# Close browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at some of the reviews\n",
    "print(f\"The first author is: {authors[0]}\")\n",
    "print(f\"The first rating is: {ratings[0]}\")\n",
    "print(f\"The first title is: {review_titles[0]}\")\n",
    "print(f\"The first room type is: {room_types[0]}\")\n",
    "print(f\"The first positive review is: {positive_parts[0]}\")\n",
    "print(f\"The first negative review is: {negative_parts[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Dataframes\n",
    "\n",
    "A nicer way to deal with data such as the ones we're scraping is by putting them into a dataframe. \n",
    "You'll learn the basics of data frames in the \"before class\" module of the next lecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we will store the results into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Author': authors,\n",
    "    'Rating': ratings,\n",
    "    'Title': review_titles,\n",
    "    'Room_Type': room_types,\n",
    "    'Positive': positive_parts,\n",
    "    'Negative': negative_parts\n",
    "})\n",
    "\n",
    "print(f\"\\n\\n{'='*50}\")\n",
    "print(f\"SCRAPING COMPLETE\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Successfully scraped {len(df)} total reviews\")\n",
    "print(\"\\nDataFrame preview:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nFull dataset shape: {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
