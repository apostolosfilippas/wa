{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéì **Professor**: Apostolos Filippas w/ Reina Chehayeb's help!\n",
    "\n",
    "### üìò **Class**: Web Analytics\n",
    "\n",
    "### üìã **Topic**: Using Selenium to Parse Web Content\n",
    "\n",
    "### üîó **Link**: https://www.bit.ly/WA_selenium\n",
    "\n",
    "üö´ **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Static content üîí vs. Dynamic content üçÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<br>\n",
    "<img src=\"https://www.cloudflare.com/resources/images/slt3lc6tev37/6ijRQV6QxiyG4zyidpgJmi/23088f026f5b01cd671274b9b994096f/caching-dynamic-content.svg\" width=\"800\" height=\"480\">\n",
    "<br>\n",
    "</div>\n",
    "\n",
    "> üîí **Static content**: files that are stored in the server and are the same every time they are delivered to users. \n",
    "> Unless the developer makes changes, the web page always remains the same. It is like a newspaper: once an issue of a newspaper is published, it features the same articles and photos all day for everyone who picks up a copy.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "        <img src=\"https://i.imgur.com/mxfom84.png\" title=\"source: imgur.com\" width=\"350\" height=\"350\" />\n",
    "</div>\n",
    "\n",
    "> üçÉ **Dynamic content** is content that changes based on factors specific to the user such as time of visit, location, and device. A dynamic webpage will not look the same for everybody, and it can change as users interact with it ‚Äì like if a newspaper could rewrite itself as someone is reading it. This makes webpages more personalized and more interactive.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "        <img src=\"https://i.imgur.com/TjkGFKx.png\" title=\"source: imgur.com\" width=\"350\" height=\"350\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. How do dynamic websites work?\n",
    "\n",
    "There are many external services that dynamic webpages interact with. Here we cover 3 common services:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üåê Server-side scripting** \n",
    "\n",
    "When a user requests a webpage, the server processes the script, and interacts with databases or external services. Then, it sends the dynamically generated HTML back to the user's browser.\n",
    "\n",
    "**Used for**: detecting that you are logging in from a certain geographic location, and shows you relevant information for that location\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/VR0xInc\"><img src=\"https://i.imgur.com/VR0xInc.png\" title=\"source: imgur.com\" width=\"400\" height=\"300\" /></a>\n",
    "</div>\n",
    "\n",
    "### **üíª Client-side scripting** \n",
    "#### This involves using **_JavaScript_** to manipulate the content and behavior of web pages directly within the user's browser (i.e., click, scroll, play, pause, and more). It allows for interactive features, such as real-time updates and dynamic animations.\n",
    "***Used for**: Scrolling and clicking, form validation (submitting a form), real-time chat and messaging, image carousels\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/N8VXk0G\"><img src=\"https://i.imgur.com/N8VXk0G.png\" title=\"source: imgur.com\" width=\"400\" height=\"300\" /></a>\n",
    "</div>\n",
    "\n",
    "### **‚òéÔ∏è Application Programming Interfaces (APIs)** \n",
    "#### APIs enable different systems to communicate and share data. In the dynamic websites, APIs can connect to external services or retrieve data from other sources, such as social media platforms, weather services, or payment gateways.\n",
    "**Used for**: Allowing users to view and interact with external services without having to leave the website (ex. live Twitter feeds, PayPal).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/HJl6RSl\"><img src=\"https://i.imgur.com/HJl6RSl.png\" title=\"source: imgur.com\" width=\"375\" height=\"300\" /></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why can't we just use Beautiful Soup to scrape dynamic content?\n",
    "- **Beautiful Soup**: It does only static scraping. Static scraping doesn't take JavaScript into consideration. When using Beautiful Soup to fetch web pages from the servers, it doesn't interact with the browser. \n",
    "\n",
    "- **Selenium**: In many cases, you need data that are hidden in components which get rendered on clicking JavaScript links. For example, for long reviews on many websites, you often need to click \"read more\" to view the full content. If you scraped a website using BeautifulSoup without clicking the \"read more\" button, you would only get part of that review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Getting started with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we start by importing all the useful packages. \n",
    "\n",
    "Note that to be able to follow along, you should have followed the steps in the \"Before class\" portion of Lecture 6.\n",
    "\n",
    "We will be using chrome throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above:\n",
    "- **time** will allow us to build \"breaks\" into our code to slow it down.\n",
    "- **pandas** will allow us to store data that we parsed from the website (you will learn more about this next week)\n",
    "\n",
    "\n",
    "Below:\n",
    "- The following scripts will open an instance of the Chrome browser. The instance of Chrome that opened will indicate that \"Chrome is now being controlled by automated test software\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a browser object-- this should open a chrome browser using selenium\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to a website\n",
    "browser.get(\"http:/www.newyorktimes.com/\")\n",
    "time.sleep(2)\n",
    "browser.get(\"http://www.crunchbase.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "browser.quit()\n",
    "\n",
    "# take a look at other browser methods\n",
    "# browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you're ready to use this powerful tool! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Navigating around a website with Selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "time.sleep(1)\n",
    "browser.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "# let's go to the review page of BBQ Sailing Trip on TripAdviser\n",
    "link = \"https://www.tripadvisor.com/Attraction_Review-g1187810-d10127777-Reviews-BBQ_Sailing_Trip-Skopelos_Town_Skopelos_Sporades.html\"\n",
    "browser.get(link)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Just like HTML is used to find static content, we can use __**XML**__ (Extensible Markup Language) to find and interact with dynamic content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML\n",
    "- XML is a markup language,designed to store, structure, and transport data or information.\n",
    "- It focuses on representing the content of data rather than specifying how it should be displayed (unlike HTML)\n",
    "- XML is widely used for data interchange and storage, providing a standardized way to format and organize data.\n",
    "- XML documents use tags to enclose data elements, creating a hierarchical structure. For example:\n",
    "\n",
    "```xml\n",
    "<bookstore>\n",
    "  <book>\n",
    "    <title lang=\"en\">Harry Potter and the mid-life crisis</title>\n",
    "    <description>Go on a journey with Harry Potter and his friends as they navigate the challenges of middle age by buying a Porsche.</description>\n",
    "    <price>29.99</price>\n",
    "  </book>\n",
    "</bookstore>\n",
    "```\n",
    "\n",
    "## XPath\n",
    "- XPath (XML Path Language) is a query language used in Selenium to navigate and locate elements within a web page's DOM (Document Object Model).\n",
    "- XPath is used to locate and interact with elements within XML or HTML documents, making it particularly useful for tasks like web scraping and automated testing. While XPath is often associated with XML because it was originally designed for XML documents, it can also be applied to HTML documents. \n",
    "- XPath allows you to traverse the hierarchy of elements within both XML and HTML, making it a valuable tool for selecting and manipulating data in these structured documents. So, while they are separate concepts, XPath is frequently used in conjunction with XML and HTML to access and work with data in these formats.\n",
    "- You can find the XPATH by right click the web page, click the inspect button and select the element you want to check. It's very similar to access content with id, class and other attributes, but gives us even more freedom.\n",
    "\n",
    "A sample XPath is shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<br>\n",
    "<img src=\"https://www.guru99.com/images/3-2016/032816_0758_XPathinSele1.png\" width=\"800\" height=\"280\">\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `//`:  This selects all elements in the document that match the criteria that follow, regardless of their location within the document's hierarchy.\n",
    "- `tagname`: This selects all elements with the specified tag name.\n",
    "- `[@attribute='value']`: This selects all elements that have the specified attribute with a value equal to the specified value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating content using XPath \n",
    "\n",
    "Now let's click apply some filters using Selenium, so that we only see summer reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/F13dxbp\"><img src=\"https://i.imgur.com/F13dxbp.png\" title=\"source: imgur.com\" width=\"350\" height=\"200\" /></a>\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/2QZRoBu\"><img src=\"https://i.imgur.com/2QZRoBu.png\" title=\"source: imgur.com\" /></a>\n",
    "<div style=\"text-align: center;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the elements on this web page, we can see that:\n",
    "\n",
    "- **tagname** = button\n",
    "- **attribute** = aria-label\n",
    "- **value** = \"Click to open the filter\"\n",
    "\n",
    "From here we can fill in those parameters into our xpath:\n",
    "\n",
    "//button[@aria-label='Click to open the filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xpath to click the Filter button\n",
    "\n",
    "#get xpath for \"Filters\"\n",
    "xp = \"//button[@aria-label='Click to open the filter']\"\n",
    "\n",
    "#click on that object\n",
    "time.sleep(1)\n",
    "browser.find_element(By.XPATH,xp).click()\n",
    "time.sleep(2)\n",
    "\n",
    "# finding elements other ways\n",
    "# By."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get xpath of months to select:\n",
    "xpath_june = \"//button[@aria-label='Enable filter: June']\"\n",
    "xpath_july = \"//button[@aria-label='Enable filter: July']\"\n",
    "xpath_august = \"//button[@aria-label='Enable filter: August']\"\n",
    "\n",
    "#select months\n",
    "time.sleep(1)\n",
    "browser.find_element(By.XPATH, xpath_june).click()\n",
    "time.sleep(1)\n",
    "browser.find_element(By.XPATH, xpath_july).click()\n",
    "time.sleep(1)\n",
    "browser.find_element(By.XPATH, xpath_august).click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then, we click the \"Apply\" button to see the resulting reviews\n",
    "\n",
    "time.sleep(1)\n",
    "xpath_apply = '//button[@class=\"rmyCe _G B- z _S c Wc wSSLS AeLHi sOtnj\"]'\n",
    "browser.find_element(By.XPATH, xpath_apply).click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to locate elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can right click the element we want > Copy > Copy XPath\n",
    "\n",
    "- This will give you the Absolute XPath\n",
    "<div style=\"text-align: center;\">\n",
    "<a href=\"https://imgur.com/JkXWlcn\"><img src=\"https://i.imgur.com/JkXWlcn.png\" title=\"source: imgur.com\" width = \"500\" height=\"400\" /></a>\n",
    "<div style=\"text-align: center;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the filter button, it looks like this:\n",
    "- `/*[@id=\"tab-data-qa-reviews-0\"]/div/div[1]/div/div/div[2]/div/div/div[1]/div/button`\n",
    "\n",
    "\n",
    "**Why don't we do this instead?**\n",
    "\n",
    "- It makes your code longer\n",
    "- Your code will be more likely to break if anything changes on the web page (ex. a review gets deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting multiple elements by xPath\n",
    "\n",
    "There are multiple buttons on the page. Let's say we want to click on the button that scrolls down to the reviews.\n",
    "\n",
    "Here is the XPath for some clickable buttons on the page:\n",
    "\n",
    "//button[@type='button']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding multiple buttons with the same parameter\n",
    "# we use .find_elements() with an s to get all elements on a page with a given XPath\n",
    "\n",
    "xpath_buttons = \"//button[@type='button']\"\n",
    "\n",
    "time.sleep(2)\n",
    "elements = browser.find_elements(By.XPATH, xpath_buttons)\n",
    "\n",
    "print(type(elements))\n",
    "print(len(elements))\n",
    "elements[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do I know which element is which??**\n",
    "\n",
    "**We can extract the innerHTML or property or text information by .get_attribute('innerHTML'), .get_property() or .text methods** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can extract the inner HTML as such:\n",
    "for element in elements:\n",
    "    ind = elements.index(element)\n",
    "    html = element.get_attribute('innerHTML')\n",
    "    print(f'{ind}: \\t {html}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there **another** way of identifying the button?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in elements:\n",
    "    element_text = element.text\n",
    "    search_term = 'read more'\n",
    "    if search_term in element_text.lower():\n",
    "        print(f\"{elements.index(element)}: \\t {element.get_attribute('innerHTML')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Using the CSS selector to find elements\n",
    "\n",
    "We can use CSS Selectors instead of XPath to find and interact with elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **What is a CSS Selector?**\n",
    "\n",
    "A CSS selector is like a set of instructions that tells a web browser how to find and style elements on a web page. Remember that elements have different attributes; we can use CSS to look for elements with specific attribute values.\n",
    "\n",
    "\n",
    "##### **Examples of CSS Selectors:**\n",
    "1. Element Selector\n",
    "\n",
    "    < button > or < a > will point to elements with those respective types\n",
    "\n",
    "2. Class Selector --> .\n",
    "    \n",
    "    '.expand' points to all elements with class='expand'\n",
    "\n",
    "3. ID Selector--> #\n",
    "    \n",
    "     #submit-button points to the element with id=\"submit-button\"\n",
    "\n",
    "4. Attribute Selector --> [type=\" \"]\n",
    "\n",
    "    eg. [ type=\"text\" ] points to all elements with type=\"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating by CSS selector\n",
    "example_button = \"#tab-data-qa-reviews-0 > div > div.LbPSX > div > div:nth-child(1) > div > div > div._T.FKffI.bmUTE > div.lszDU > button\"\n",
    "# inspect -> \"Copy Selector\"\n",
    "\n",
    "time.sleep(2)\n",
    "browser.find_element(By.CSS_SELECTOR,example_button).click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How did this work?** \n",
    "\n",
    "- `#tab-data-qa-reviews-0`: find the element of which the attribute id = tab-data-qa-reviews-0;\n",
    "\n",
    "- `'> div'` find element in the child nodes of last element, with tag 'div';\n",
    "\n",
    "- `'> div.LbPSX'` target an element with the class = LbPSX \n",
    "\n",
    "- `'> div:nth-child(1)>'` looks for nth (in this case, 1st) child of its siblings\n",
    "\n",
    "- `'> div'` again, going further into child nodes of last element\n",
    "\n",
    "- `'div._T.FKffI.bmUTE`: target element with class = \"_T\", class = \"FKffI\", AND class = \"bmUTE\"\n",
    "\n",
    "- `'button'` finally, target the button element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to locate elements using selenium. For the full list, you can refer to: https://selenium-python.readthedocs.io/locating-elements.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the webpage is dynamically generated, we often need to click the **read more** button to reveal content. \n",
    "- For example, some long reviews are only partially available on TripAdvisor-- you would need to click on \"Read More\" to access the full review. Other short reviews are fully available.\n",
    "\n",
    "## Trying to click a button that doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already expanded this review. Since we interacted with a dynamic page, the button is no longer on it now.\n",
    "# what will happen if we try to click the button that doesn't exist?\n",
    "\n",
    "browser.find_element(By.CSS_SELECTOR,example_button).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to check if the button exists on the page\n",
    "def check_exists_by_css(selector):\n",
    "    try:\n",
    "        browser.find_element(By.CSS_SELECTOR,selector)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_exists_by_xpath(xp):\n",
    "    try:\n",
    "        browser.find_element(By.XPATH,xp)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we try to find a nonsense element, it will just return False instead of breaking the code\n",
    "\n",
    "check_exists_by_css('hahaha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the read more button exists\n",
    "# note: the xpath can be a different one if you search for other places\n",
    "\n",
    "readmore_css = \"#tab-data-qa-reviews-0 > div > div.LbPSX > div > div:nth-child(4) > div > div > div._T.FKffI.bmUTE > div.lszDU > button\"\n",
    "\n",
    "read_more_exists = check_exists_by_css(readmore_css)\n",
    "\n",
    "# if the reviews are expanable, expand the reviews\n",
    "if read_more_exists:\n",
    "    browser.find_element(By.CSS_SELECTOR,readmore_css).click()\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print('No element found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the previous code a helper function too\n",
    "\n",
    "def click_read_more():\n",
    "    \n",
    "    # set the xpath to the buttons and the search term \"read more\"\n",
    "    readmore_xpath = \"//button[@class='UikNM _G B- _S _T c G_ y wSSLS wnNQG']\"\n",
    "    search_term = 'read more'\n",
    "    # find all buttons on the page and save to a list\n",
    "    buttons = browser.find_elements(By.XPATH, readmore_xpath)\n",
    "\n",
    "    # for each button, check if the text is \"read more\"\n",
    "    for button in buttons:\n",
    "        if search_term in button.text.lower():\n",
    "            try:\n",
    "                button.click() # if so, click it\n",
    "            except: # otherwise do nothing\n",
    "                continue\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_read_more()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Combining Selenium and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas we cna use Selenium alone to scrape content, we prefer to use it together with beautifulsoup to make our lives easier. \n",
    "\n",
    "The complete workflow would be like:\n",
    "1. Using Selenium to automate web browser interaction so that hidden content can be made available by automating actions such as the button clicks, screen scrolling and so on\n",
    "2. After all the content we want to parse is revealed, we'll use BeautifulSoup to parse it like we did in Lecture 5\n",
    "\n",
    "---\n",
    "# 7. Challenge\n",
    "\n",
    "1. Use Selenium to click all the \"Read More\" buttons \n",
    "2. Use BeautifulSoup to parse the content of the reviews\n",
    "3. Locate and click the \"next page\" button, if it exists and if you're scraping more pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of pages you want to parse, and the link you want to parse from\n",
    "page_num = 1\n",
    "link = \"https://www.tripadvisor.com/Attraction_Review-g1187810-d10127777-Reviews-BBQ_Sailing_Trip-Skopelos_Town_Skopelos_Sporades.html\"\n",
    "\n",
    "# create some empty lists to store the reviews, ratings, and authors as you go\n",
    "reviews = []\n",
    "ratings = []\n",
    "authors = []\n",
    "\n",
    "# Open browser\n",
    "browser = webdriver.Chrome()\n",
    "# Go to the link\n",
    "browser.get(link)\n",
    "time.sleep(2)\n",
    "\n",
    "# loop through the pages you want to scrape\n",
    "for i in range(0, page_num):\n",
    "    \n",
    "    # expand the reviews on that page\n",
    "    click_read_more() \n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "    # parse the page to a soup\n",
    "    page_source     = browser.page_source\n",
    "    soup            = BeautifulSoup(page_source, 'html.parser')\n",
    "    reviews_content = soup.find_all('div', class_=\"_c\")\n",
    "    \n",
    "    # extract the author, review_text and rating for each review on the page\n",
    "    # You need to fill in the elements for the text, author, and rating (hint: use inspect)\n",
    "    for review in reviews_content:\n",
    "        review_text = None # <<< Get the text content of the review >>>\n",
    "        author      = None # <<< Get the author name >>>\n",
    "        rating      = None # <<< how many stars out of 5? >>>\n",
    "        \n",
    "        # append to our accumulative lists\n",
    "        reviews.append(review_text)\n",
    "        ratings.append(rating)\n",
    "        authors.append(author)\n",
    "        \n",
    "    # use selenium to go to the next page\n",
    "    next_page = None \n",
    "    # << Find the xpath or CSS selector for the next page button >>\n",
    "    # << check if the next page button exists for the page you are currently on. If it does, click it. If not, exit the loop.>>\n",
    "    # << FILL IN YOUR CODE HERE! >>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Dataframes\n",
    "\n",
    "A nicer way to deal with data such as the ones we're scraping is by putting them into a dataframe. \n",
    "You'll learn the basics of data frames in the \"before class\" module of the next lecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we will store the results into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'reviews': reviews,\n",
    "    'ratings': ratings,\n",
    "    'authors': authors\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# check the shape of our dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Extra Practice\n",
    "\n",
    "If you'd like to get some more practice in using Selenium, you can try the following exercise:\n",
    "1. Open a browser with Selenium, go to the review page of [Wall Street](https://www.tripadvisor.com/Attraction_Review-g60763-d136051-Reviews-Wall_Street-New_York_City_New_York.html) on TripAdvisor (or any other attraction place of your choice)\n",
    "2. Select only the **Business trip** in the filter.\n",
    "3. Scrape the full reviews from the first 5 pages. Can you also include the date of the review?\n",
    "4. Can you see any relationship between the review months and rating scores?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
