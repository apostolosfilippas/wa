{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtuDTzK9C9Cy"
   },
   "source": [
    "---\n",
    "\n",
    "### üéì **Professor**: Apostolos Filippas\n",
    "\n",
    "### üìò **Class**: Web Analytics\n",
    "\n",
    "### üìã **Topic**: Pandas (self-study)\n",
    "\n",
    "### üîó **Link**: https://bit.ly/WA_LEC7_PANDAS\n",
    "\n",
    "üö´ **Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKmsnhqvC9Cz"
   },
   "source": [
    "# üö™ 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR7QR2BvC9C0"
   },
   "source": [
    "To make the contents of a package available, you need to import it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9dK4N4CC9C6"
   },
   "source": [
    "Make sure to install the following packages before running the code in the next cell:\n",
    "- **`pandas`** is a data manipulation package. It lets us store data in data frames. More on this soon.\n",
    "- **`sklearn`** is a machine learning and data science package. It lets us do fairly complicated machine learning tasks, such as running regressions and building classification models with only a few lines of code.\n",
    "- **`seaborn`** an extension to matplotlib that really helps make your plots look more appealing\n",
    "- **`numpy`** (pronounced num-pie) is used for doing \"math stuff\", such as mathematical operations (e.g., square roots, exponents, logs), matrix algebra, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hFH_C21C9C7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# display  plots inline with the rest of your notebook, rather than in a separate window\n",
    "%matplotlib inline\n",
    "\n",
    "# some stylistic tweaks in seaborn\n",
    "sns.set(style='ticks', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkHPucWlC9C9"
   },
   "source": [
    "We can now use package-specific functions. For example, numpy has a function called `sqrt()` which will give us the square root of a numpy number. Since it is part of numpy, we need to tell Python that that's where it is by using a dot (e.g., `np.sqrt()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRSDuE6cC9C-",
    "outputId": "933db8f1-348f-4b0b-b431-94b9b07868cf"
   },
   "outputs": [],
   "source": [
    "some_list = [0,0,1,2,3,3,4.5,7.6]\n",
    "some_dictionary = {'student1': '(929)-000-0000', \n",
    "                   'student2': '(917)-000-0000', \n",
    "                   'student3': '(470)-000-0000'}\n",
    "\n",
    "\n",
    "# In this part of the code I am using numpy (np) functions\n",
    "print (\"Square root: \" + str ( np.sqrt(25) ))\n",
    "print (\"Maximum element of our previous list: \" + str( np.max(some_list) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfIR4inpct1h"
   },
   "source": [
    "---\n",
    "# üêº 2. The Pandas Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e0Zl04xC9DA"
   },
   "source": [
    "The Pandas package gives us the **DATAFRAME** --- one of the main data structures used in data analytics.\n",
    "\n",
    "- A Dataframe is an excel sheet on steroids. \n",
    "- More scientifically, a dataframe is a 2-dimensional \"labeled\" data structure with columns of potentially different types. It is the most commonly used pandas object. Along with the data, you can optionally pass index (row labels) and column (column labels) arguments. \n",
    "\n",
    "Pandas data frames can be constructed from most common data sources a data scientist will encounter: csv files, excel spreadsheets, sql databases, json, url pointers to other data sources, and even from other data already stored in one's python code. \n",
    "\n",
    "First, let's take a look at creating a data frame from a common \"toy\" dataset presenting automobile mpg information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwk6VEqPC9DC"
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original\"\n",
    "\n",
    "column_names = ['mpg', 'cylinders', 'displacement', \n",
    "                'horsepower', 'weight', 'acceleration',\n",
    "                'model', 'origin', 'car_name']\n",
    "\n",
    "mpg_df = pd.read_csv(url,\n",
    "                     delim_whitespace=True,\n",
    "                     header=None,\n",
    "                     names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbxNrstwC9DE"
   },
   "source": [
    "We now have the data loaded in a pandas data frame, as a starter, let's see some of the (MANY!) ways pandas makes it convenient to explore a dataset.\n",
    "\n",
    "\n",
    "## Fast summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOU-ZZlxC9DF",
    "outputId": "eb0e9f85-6ea1-4094-ded4-58964986fd1f"
   },
   "outputs": [],
   "source": [
    "# first, just get a peek at the data:\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wyAa7LyC9DH",
    "outputId": "8eab3edc-e6fe-4ee7-b081-e88d9257e434"
   },
   "outputs": [],
   "source": [
    "# some general stats about the data\n",
    "mpg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo1-SzL0C9DL",
    "outputId": "29061146-358d-436f-b6ba-ef307c29ec02"
   },
   "outputs": [],
   "source": [
    "# info about the different columns\n",
    "mpg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_gatRiwct1k",
    "outputId": "4c257b74-da9a-40c5-9e1e-f48a2d976982"
   },
   "outputs": [],
   "source": [
    "# grab a single column\n",
    "mpg_df[\"cylinders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXTpftUUct1l",
    "outputId": "d40ef336-81f6-498c-ff09-4ee71cebc018"
   },
   "outputs": [],
   "source": [
    "# another way to grab a single column\n",
    "mpg_df.cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cNCgQQfct1l",
    "outputId": "34536983-3795-4065-fd8b-b94f555297af"
   },
   "outputs": [],
   "source": [
    "mpg_df[\"cylinders\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pADI41QAC9DO",
    "outputId": "f96a49e3-bf86-4e9a-db6f-31d2172be750"
   },
   "outputs": [],
   "source": [
    "# how many of each type of engine? \n",
    "mpg_df[\"cylinders\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfYbd8veC9DQ",
    "outputId": "317bc7b8-b7e3-4847-ae90-00e4c0344ad5"
   },
   "outputs": [],
   "source": [
    "# total horsepower\n",
    "mpg_df[\"horsepower\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9E5uqaCC9DS",
    "outputId": "51d408d2-1017-4379-8b20-af5959928e6c"
   },
   "outputs": [],
   "source": [
    "# average horsepower per engine type\n",
    "mpg_df.groupby(\"cylinders\").horsepower.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTLeHtyBC9DU"
   },
   "source": [
    "## Fast plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj1u37EfC9DV",
    "outputId": "0f6818a9-d521-4235-af65-8dfe758b42df"
   },
   "outputs": [],
   "source": [
    "# plotting a histogram of mpg\n",
    "mpg_df.hist(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVmvL1J5C9DX",
    "outputId": "17ac1074-2a07-4dd7-bd08-258fede2859b"
   },
   "outputs": [],
   "source": [
    "# or a scatter plot of acceleration vs mpg\n",
    "mpg_df.plot(kind=\"scatter\", x=\"acceleration\", y=\"mpg\", c = 'forestgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10jqAsE5C9Da",
    "outputId": "ba0959e8-04dd-4918-ffa1-807f3b110c55"
   },
   "outputs": [],
   "source": [
    "# some pretty plotting comparing weight to mpg using regression in seaborn\n",
    "sns.jointplot(x=\"weight\", y=\"mpg\", data=mpg_df, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vz2mwA_C9Dc"
   },
   "source": [
    "Pandas is widely used and has a very active development community contributing new features. As such, if there is some kind of analysis you want to do on your data, chances are, it already exists. \n",
    "\n",
    "The [documentation for the pandas library](https://pandas.pydata.org/pandas-docs/stable/) is very good, but the site's search functionality is, unfortunately poor. I recommend using chatGPT or Google to find the information you need.\n",
    "\n",
    "\n",
    "## Selecting columns \n",
    "\n",
    "One important component of pandas is indexing and selecting components of the data.\n",
    "We saw how to select columns, but here it is again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSPL6m3qC9Dd",
    "outputId": "2081633b-e240-4268-a8bf-483ed870b8d5"
   },
   "outputs": [],
   "source": [
    "# selecting columns is done using the `[]` operator,\n",
    "# which accepts one column name or a list of several names\n",
    "mpg_df[[\"cylinders\", \"car_name\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTw9PZEqC9Df",
    "outputId": "b096aac0-813e-4073-a10a-277c7c941441"
   },
   "outputs": [],
   "source": [
    "# as some \"syntactic sugar\", pandas also allows selection using the `.column_name` notation\n",
    "# note that both cases can be used for assignment!\n",
    "mpg_df.car_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oz6JyPFC9Di"
   },
   "source": [
    "## Selecting rows\n",
    "\n",
    "There are two options for selecting rows in pandas:\n",
    "- `.loc`: for selecting rows based on the _row label_\n",
    "- `.iloc`: for selecting rows based on the _row number_\n",
    "\n",
    "In the prior example, the row label and the row number are the same.\n",
    "However, it often makes sense to assign labels to rows, a unique id (think about: dictionaries). In many cases, this would be something like a date or a user id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKXfNs1fC9Dk",
    "outputId": "03ddbff4-7ec7-470e-80ed-16c6d4881f18"
   },
   "outputs": [],
   "source": [
    "# get a single row\n",
    "mpg_df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b26eUX46C9Dm",
    "outputId": "6486c0b6-3e2e-4831-fe4c-39b709f4c7e2"
   },
   "outputs": [],
   "source": [
    "# selecting the first 5 rows\n",
    "mpg_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnObBp6CC9Dn",
    "outputId": "c0ba84d3-92c7-4706-9456-ee5190fad618"
   },
   "outputs": [],
   "source": [
    "# a small difference between label & index selecting\n",
    "mpg_df.loc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6eRt4ZcC9Dp"
   },
   "source": [
    "One can also select those rows that match a particular condition. Say I want to only see those rows that have an acceleration less that 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkAo5wlrC9Dq",
    "outputId": "c0cc94dc-f43a-404e-95e6-a4c206c3668d"
   },
   "outputs": [],
   "source": [
    "mpg_df[mpg_df[\"acceleration\"] < 10].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohHy2tTrC9Dr"
   },
   "source": [
    "If we have _actual labels_ as an index for a dataframe, we can use `.loc` to select using values from that index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KU9lhb-BC9Ds",
    "outputId": "c7daf455-e205-4593-aacf-da19695292d6"
   },
   "outputs": [],
   "source": [
    "car_index_df = mpg_df.set_index(\"car_name\", inplace=False)\n",
    "#car_index_df.iloc[:5]\n",
    "car_index_df.loc[[\"amc rebel sst\", \"plymouth fury iii\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jf2vDTiC9Dt"
   },
   "source": [
    "## Creating a dataframe\n",
    "\n",
    "Often, one wants to create a data frame from information that is available \"in code.\" This information might be results of prior computations that aren't already in pandas, or maybe just some small static dataframe that stores some info. \n",
    "\n",
    "There are two common ways to do this: \n",
    "- lists-of-lists with an additional list of column names\n",
    "- lists of dictionaries \n",
    "\n",
    "I prefer the latter since the data in this case is self-descriptive, order isn't important, and missing data is handled more smoothly, but I'll give examples below for both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFKL2h9QC9Dt",
    "outputId": "f741a9b0-dd09-4b47-a8dc-c3f2f1c908fe"
   },
   "outputs": [],
   "source": [
    "# list-of-lists approach\n",
    "\n",
    "list1 = ['studentA',22,'(929)-000-000']\n",
    "list2 = ['studentB',np.nan,'(646)-000-000']\n",
    "list3 = ['studentC',30,'(917)-000-000']\n",
    "list4 = ['studentD',31,'(646)-001-001']\n",
    "list5 = ['studentE',np.nan,'(929)-001-001']\n",
    "list6 = ['studentF',30,'(917)-001-001']\n",
    "list7 = ['studentG',30,'(470)-001-001']\n",
    "\n",
    "list_of_lists = [list1, list2, list3, list4, list5, list6, list7]\n",
    "column_names = ['Name','Age','Mobile']\n",
    "\n",
    "lol_df = pd.DataFrame(list_of_lists,columns=column_names)\n",
    "lol_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqcyvNCmC9Du",
    "outputId": "4b99f2d5-8564-45a2-d406-ad9ead163592"
   },
   "outputs": [],
   "source": [
    "# this is the list of dicts approach\n",
    "alice = {\"name\": \"alice\", \"age\": 5, \"mobile\":\"555-222-9000\"}\n",
    "bob = {\"name\": \"bob\", \"age\": 100}\n",
    "casey = {\"age\":35, \"name\": \"casey\", \"mobile\":\"1-877-kars-4kids\"}\n",
    "\n",
    "list_of_dicts = [alice, bob, casey]\n",
    "lod_df = pd.DataFrame(list_of_dicts)\n",
    "lod_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWfekDSPC9Dx"
   },
   "source": [
    "We can also add columns ( they should have the same number of rows as the dataframe they are being added to )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZsRqVmSC9Dx",
    "outputId": "a64f7312-1fe8-4de0-986e-e7e043a9101e"
   },
   "outputs": [],
   "source": [
    "\n",
    "lol_df['Business Major'] = ['yes','no','yes','yes','yes','no','yes']\n",
    "lol_df['Years Experience'] = [1,4,2,6,0,3,0]\n",
    "\n",
    "lol_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w21OOueC9Dz"
   },
   "source": [
    "## Operations with columns\n",
    "\n",
    "What about operations on entire columns? This can make data munging much easier!\n",
    "\n",
    "Let's take the difference between age and years of experience:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5u1P1WyC9D0",
    "outputId": "06b86cb6-a250-460d-8255-ea3d73cb636b"
   },
   "outputs": [],
   "source": [
    "\n",
    "lol_df[\"Age\"] - lol_df[\"Years Experience\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZGE-VuwC9D1"
   },
   "source": [
    "All of the data frames used thus far have had missing values. We see that by default, pandas just displays `NaN`, when the value of a cell is unknown. Sometimes this interferes with the computation we're trying to accomplish. Fortunately, there is a [suite of functionality](https://pandas.pydata.org/pandas-docs/stable/missing_data.html) for dealing with missing data built in.\n",
    "\n",
    "Let's (for some reason) fill missing age info with the average age!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN4nowfIC9D1",
    "outputId": "95fadf12-f02b-43c2-bdf5-db09bae918de"
   },
   "outputs": [],
   "source": [
    "lol_df[\"Age\"].fillna(lol_df[\"Age\"].mean()) - lol_df[\"Years Experience\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a file to disk\n",
    "\n",
    "Finally, we often want to write our data back to disk. Here's how to write a df as a csv with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.to_csv(\"files/mpg_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's equally easy to read a csv file into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"files/mpg_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìö 3. More resources\n",
    "\n",
    "We only touched on the surface of Pandas. There are many more things you can do with it. Here are some resources to help you learn more:\n",
    "- [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Pandas cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- [Pandas cookbook](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html)\n",
    "- [Pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
    "- [10 minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "- [Pandas exercises Github](https://github.com/guipsamora/pandas_exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üèãÔ∏è‚Äç‚ôÄÔ∏è 4. Exercise: Amazon Employee Reviews Analysis\n",
    "\n",
    "Objective: Understand and analyze the Amazon employee reviews dataset using the pandas techniques you've learned.\n",
    "\n",
    "## 1. Setup and Data Loading\n",
    "1. Import necessary libraries (pandas, numpy, seaborn, and matplotlib).\n",
    "2. Load the dataset into a pandas dataframe named reviews_df. The dataset can be found [here](https://drive.google.com/file/d/10hKwrxftkO8g73HrQiXHcDbA9B9skTbO/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration and Cleaning\n",
    "1. Display the first 5 rows of the dataframe.\n",
    "2. Use the .info() method to understand the different columns and data types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Analysis\n",
    "1. How many reviews are there for each job type (Full Time, Part Time, etc.)?\n",
    "2. What are the top 5 job roles with the highest average overall rating?\n",
    "3. Display the average overall rating for each department.\n",
    "4. Plot a histogram showcasing the distribution of overall ratings.\n",
    "5. Plot a scatter plot to see if there's a relationship between work life balance and work satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Indexing and Selection\n",
    "1. Set the Name column as the index for the dataframe.\n",
    "2. Select and display all reviews for the \"Software Development Engineer\" role.\n",
    "3. Using .iloc, display details of the 50th review in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus (Advanced)\n",
    "1. Group reviews by their Place and display the top 5 places with the highest average overall rating.\n",
    "2. Create a new dataframe containing only the reviews with a job role that starts with the letter 'S'.\n",
    "3. Plot a bar chart showcasing the number of reviews made each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üèãÔ∏è‚Äç‚ôÄÔ∏è ‚úÖ. Solutions: Amazon Employee Reviews Analysis\n",
    "\n",
    "Objective: Understand and analyze the Amazon employee reviews dataset using the pandas techniques you've learned.\n",
    "\n",
    "## 1. Setup and Data Loading\n",
    "1. Import necessary libraries (pandas, numpy, seaborn, and matplotlib).\n",
    "2. Load the dataset into a pandas dataframe named reviews_df. The dataset can be found [here](https://drive.google.com/file/d/10hKwrxftkO8g73HrQiXHcDbA9B9skTbO/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reviews_df = pd.read_csv('files/amazon_employee_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration and Cleaning\n",
    "1. Display the first 5 rows of the dataframe.\n",
    "2. Use the .info() method to understand the different columns and data types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Analysis\n",
    "1. How many reviews are there for each job type (Full Time, Part Time, etc.)?\n",
    "2. What are the top 5 job roles with the highest average overall rating?\n",
    "3. Display the average overall rating for each department.\n",
    "4. Plot a histogram showcasing the distribution of overall ratings.\n",
    "5. Plot a scatter plot to see if there's a relationship between work life balance and work satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_counts = reviews_df['Job_type'].value_counts()\n",
    "print(job_type_counts)\n",
    "\n",
    "top_roles = reviews_df.groupby('Name')['Overall_rating'].mean().sort_values(ascending=False).head(5)\n",
    "print(top_roles)\n",
    "\n",
    "avg_rating_per_department = reviews_df.groupby('Department')['Overall_rating'].mean()\n",
    "print(avg_rating_per_department)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(reviews_df['Overall_rating'], bins=5, kde=False)\n",
    "plt.title('Distribution of Overall Ratings')\n",
    "plt.xlabel('Overall Rating')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=reviews_df['work_life_balance'], y=reviews_df['work_satisfaction'])\n",
    "plt.title('Relationship between Work Life Balance and Work Satisfaction')\n",
    "plt.xlabel('Work Life Balance Rating')\n",
    "plt.ylabel('Work Satisfaction Rating')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Indexing and Selection\n",
    "1. Set the Name column as the index for the dataframe.\n",
    "2. Select and display all reviews for the \"Software Development Engineer\" role.\n",
    "3. Using .iloc, display details of the 50th review in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.set_index('Name', inplace=True)\n",
    "\n",
    "sde_reviews = reviews_df.loc['Software Development Engineer']\n",
    "print(sde_reviews)\n",
    "\n",
    "fiftieth_review = reviews_df.iloc[49]\n",
    "print(fiftieth_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus (Advanced)\n",
    "1. Group reviews by their Place and display the top 5 places with the highest average overall rating.\n",
    "2. Create a new dataframe containing only the reviews with a job role that starts with the letter 'S'.\n",
    "3. Plot a bar chart showcasing the number of reviews made each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_places = reviews_df.groupby('Place')['Overall_rating'].mean().sort_values(ascending=False).head(5)\n",
    "print(top_places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_reset = reviews_df.reset_index()\n",
    "s_starting_roles = reviews_df_reset[reviews_df_reset['Name'].str.startswith('S')]\n",
    "print(s_starting_roles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month from Date column\n",
    "reviews_df_reset['Month'] = pd.to_datetime(reviews_df_reset['Date']).dt.month_name()\n",
    "\n",
    "# Group by month and count\n",
    "monthly_reviews = reviews_df_reset['Month'].value_counts()\n",
    "\n",
    "sns.barplot(x=monthly_reviews.index, y=monthly_reviews.values, order=monthly_reviews.index.sort_values())\n",
    "plt.title('Number of Reviews Made Each Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "06.1 Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
